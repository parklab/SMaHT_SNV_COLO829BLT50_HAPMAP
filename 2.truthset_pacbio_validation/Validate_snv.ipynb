{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41596333-ae5a-46e1-9752-9f6cf91864f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added removing multiallelic in PB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a47df81-b9b2-405a-bac9-830832eda08e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++ VN started +++\n",
      "chr1 2445 2179 2117 62 223 0\n",
      "chr2 4269 3993 3900 93 237 0\n",
      "chr3 3686 3484 3410 74 179 0\n",
      "chr4 3901 3682 3594 88 190 0\n",
      "chr5 2034 1736 1694 42 266 0\n",
      "chr6 3134 2920 2835 85 185 0\n",
      "chr7 2211 2067 2015 52 123 0\n",
      "chr8 3136 2978 2897 80 139 1\n",
      "chr9 1746 1599 1552 47 129 0\n",
      "chr10 1565 1332 1294 38 199 0\n",
      "chr11 1471 1275 1244 31 168 0\n",
      "chr12 2419 2251 2183 68 151 0\n",
      "chr13 1898 1762 1730 32 120 0\n",
      "chr14 980 894 874 20 76 0\n",
      "chr15 850 766 736 30 78 0\n",
      "chr16 1105 996 969 27 97 0\n",
      "chr17 1126 1024 996 28 92 0\n",
      "chr18 959 811 785 26 111 0\n",
      "chr19 1002 914 888 26 72 0\n",
      "chr20 1135 1076 1039 37 55 0\n",
      "chr21 703 671 653 18 28 0\n",
      "chr22 510 482 471 11 26 0\n",
      "chrX 2003 1720 1690 30 264 0\n",
      "chrY 0 0 0 0 0 0\n",
      "\n",
      "+++ RF started +++\n",
      "chr1 2049 2004 1928 76 43 0\n",
      "chr2 3797 3767 3671 96 29 0\n",
      "chr3 3274 3227 3140 87 43 0\n",
      "chr4 3447 3420 3340 80 27 0\n",
      "chr5 1591 1583 1549 34 7 0\n",
      "chr6 2651 2643 2565 78 5 0\n",
      "chr7 2659 2602 2529 73 50 0\n",
      "chr8 2794 2781 2702 79 13 0\n",
      "chr9 1552 1531 1486 45 19 0\n",
      "chr10 1191 1189 1157 31 1 1\n",
      "chr11 1174 1164 1142 22 8 0\n",
      "chr12 2087 2077 2014 63 9 0\n",
      "chr13 1680 1659 1620 39 16 0\n",
      "chr14 834 810 794 16 21 0\n",
      "chr15 718 707 678 29 5 0\n",
      "chr16 960 953 924 29 6 0\n",
      "chr17 984 974 942 32 10 0\n",
      "chr18 700 689 667 22 8 0\n",
      "chr19 827 823 798 25 4 0\n",
      "chr20 1037 1016 978 38 19 0\n",
      "chr21 682 674 650 24 5 0\n",
      "chr22 488 474 458 16 14 0\n",
      "chrX 1602 1596 1566 30 6 0\n",
      "chrY 12 0 0 0 12 0\n",
      "\n",
      "+++ STK started +++\n",
      "chr1 4793 3968 2388 1580 521 0\n",
      "chr2 4341 4282 4162 120 34 0\n",
      "chr3 3788 3726 3607 118 40 1\n",
      "chr4 3930 3895 3800 95 22 0\n",
      "chr5 2562 2166 1805 361 305 0\n",
      "chr6 3089 3062 2975 87 16 0\n",
      "chr7 3085 3013 2889 124 46 0\n",
      "chr8 3161 3126 3035 90 18 1\n",
      "chr9 1846 1779 1678 101 49 0\n",
      "chr10 1911 1699 1413 285 136 1\n",
      "chr11 1849 1607 1333 274 175 0\n",
      "chr12 2400 2364 2291 73 19 0\n",
      "chr13 1921 1876 1836 40 21 0\n",
      "chr14 1566 1323 955 368 179 0\n",
      "chr15 1083 975 801 174 79 0\n",
      "chr16 1242 1150 1046 104 52 0\n",
      "chr17 1120 1097 1060 37 14 0\n",
      "chr18 1276 1097 933 164 94 0\n",
      "chr19 997 979 944 35 13 0\n",
      "chr20 1174 1151 1115 36 13 0\n",
      "chr21 776 762 738 24 8 0\n",
      "chr22 579 559 517 42 15 0\n",
      "chrX 2033 1932 1811 121 57 0\n",
      "chrY 5151 1269 128 1141 3716 0\n",
      "\n",
      "+++ MT started +++\n",
      "chr1 2608 2448 2280 168 73 0\n",
      "chr2 4243 4190 4078 112 38 0\n",
      "chr3 3684 3654 3565 89 16 0\n",
      "chr4 3892 3865 3765 100 18 0\n",
      "chr5 1857 1815 1748 67 30 0\n",
      "chr6 3028 3007 2924 83 11 0\n",
      "chr7 2992 2945 2871 74 38 0\n",
      "chr8 3115 3088 2995 93 17 0\n",
      "chr9 1727 1685 1636 49 37 0\n",
      "chr10 1439 1403 1348 55 18 0\n",
      "chr11 1397 1347 1308 39 39 0\n",
      "chr12 2370 2335 2266 69 23 0\n",
      "chr13 1936 1871 1813 58 40 0\n",
      "chr14 968 951 922 29 8 0\n",
      "chr15 828 819 778 41 6 0\n",
      "chr16 1063 1042 1008 34 14 0\n",
      "chr17 1111 1086 1045 41 20 0\n",
      "chr18 980 909 869 40 39 0\n",
      "chr19 988 975 943 32 8 0\n",
      "chr20 1155 1133 1093 40 15 0\n",
      "chr21 736 734 712 22 1 0\n",
      "chr22 535 530 510 20 4 0\n",
      "chrX 1848 1820 1784 36 17 0\n",
      "chrY 123 27 7 20 94 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "# --- Paths & setup ---\n",
    "path = \"/n/data1/hms/dbmi/park/jiny/SMaHT/COLO829/0.truthset/\"\n",
    "vcfpath = os.path.join(path, \"0.calls_Illumina\")\n",
    "outpath = os.path.join(path, \"1.Illumina_PU20\")\n",
    "chroms = [f\"chr{i}\" for i in range(1, 23)] + [\"chrX\", \"chrY\"]\n",
    "\n",
    "l_mode = {\"MT\", \"STK\", \"VN\", \"RF\"}\n",
    "\n",
    "# Ensure output dirs exist\n",
    "os.makedirs(os.path.join(outpath, \"Valid_tools\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(outpath, \"Stat\"), exist_ok=True)\n",
    "\n",
    "# --- Dictionaries ---\n",
    "dic_raw_all, dic_step1, dic_AF, dic_valid, dic_altzero, dic_VAF = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "# NEW: tumor ALT counts aggregated per (loc, REF) to find major ALT\n",
    "# Structure: dic_tumor_counts[mode][loc][ref][alt] = alt_count_in_tumor\n",
    "dic_tumor_counts = {}\n",
    "\n",
    "# NEW: count multi-allelic exclusions per mode\n",
    "dic_multiallelic = {}\n",
    "\n",
    "# --- Helpers ---\n",
    "def parse_af(ad_field):\n",
    "    \"\"\"Extract (AF, alt_count) from AD='ref,alt' style string. Returns (af, alt_count) or (None, None).\"\"\"\n",
    "    try:\n",
    "        ref, alt = (ad_field or \"0,0\").split(',')[:2]\n",
    "        ref, alt = int(ref), int(alt)\n",
    "        depth = ref + alt\n",
    "        if depth == 0:\n",
    "            return 0.0, 0\n",
    "        return float(alt) / depth, alt\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "def write_combined_header_if_needed(path_):\n",
    "    if not os.path.exists(path_) or os.path.getsize(path_) == 0:\n",
    "        with open(path_, \"w\") as fout:\n",
    "            fout.write(\n",
    "                \"mode\\tTotal\\tAlt_in_T\\tValid\\tInvalid_Alt_in_LBL\\t\"\n",
    "                \"Invalid_NoAlt_in_LT\\tInvalid_NoAlt_in_ST\\tMultiAllelic\\tValid_percent\\n\"\n",
    "            )\n",
    "\n",
    "combined_stat_path = os.path.join(outpath, \"Stat\", \"Stat_snv.Valid.ALL.txt\")\n",
    "write_combined_header_if_needed(combined_stat_path)\n",
    "\n",
    "# --- Main loop ---\n",
    "for mode in l_mode:\n",
    "    tool = mode.split(\".\")[0]\n",
    "\n",
    "    dic_valid[mode] = []\n",
    "    dic_multiallelic[mode] = 0\n",
    "    if mode not in dic_AF:\n",
    "        dic_AF[mode] = {}\n",
    "    if mode not in dic_tumor_counts:\n",
    "        dic_tumor_counts[mode] = {}\n",
    "\n",
    "    print(f\"\\n+++ {mode} started +++\")\n",
    "\n",
    "    out_vcf_path = f\"{outpath}/Valid_tools/{mode}.Valid.vcf\"\n",
    "    out_vcf = open(out_vcf_path, \"w\")\n",
    "\n",
    "    # per-chrom stat file (kept, as in your original)\n",
    "    out_stat_path = f\"{outpath}/Stat/Stat_snv_{mode}.Valid.txt\"\n",
    "    out_stat = open(out_stat_path, \"w\")\n",
    "    out_stat.write(\n",
    "        \"mode\\tchrom\\tTotal\\tAlt_in_T\\tValid\\tInvalid_Alt_in_LBL\\t\"\n",
    "        \"Invalid_NoAlt_in_LT\\tInvalid_NoAlt_in_ST\\tMultiAllelic\\tValid_percent\\n\"\n",
    "    )\n",
    "\n",
    "    # Mode-level totals (for combined summary)\n",
    "    m_total = m_alt_in_t = m_valid = m_alt_in_bl = m_alt_notin_lt = m_alt_notin_st = m_multiallelic = 0\n",
    "\n",
    "    for chrom in chroms:\n",
    "        # --- counters per chrom ---\n",
    "        cnt_total = cnt_alt_in_t = cnt_noalt_in_bl = cnt_alt_in_bl = cnt_alt_notin_lt = cnt_alt_notin_st = 0\n",
    "        cnt_multiallelic_chr = 0\n",
    "        header_written = False\n",
    "\n",
    "        # --- Read PU support (tumor, blood) and keep ALL ALTs (SNVs + INDELs) ---\n",
    "        pu_file = os.path.join(vcfpath, \"PU_bcftools\", f\"{mode}.snv.{chrom}.PU.norm.vcf.gz\")\n",
    "        dic_step1.setdefault(chrom, {})\n",
    "        dic_tumor_counts[mode].setdefault(chrom, {})  # not used directly, but keep per chrom key\n",
    "\n",
    "        # Note: we do NOT filter by len(ref/alt) here, so we can see competing INDEL alts\n",
    "        if os.path.exists(pu_file):\n",
    "            with open(pu_file, \"r\") as fpu:\n",
    "                for line in fpu:\n",
    "                    if line.startswith(\"#\"):\n",
    "                        continue\n",
    "                    s = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "                    if s[0] != chrom:\n",
    "                        continue\n",
    "                    pos, ref, alt = s[1], s[3], s[4]\n",
    "                    if alt == \"<*>\":\n",
    "                        continue\n",
    "\n",
    "                    loc = f\"{chrom}:{pos}\"\n",
    "                    var = f\"{ref}:{alt}\"\n",
    "                    dic_AF[mode].setdefault(loc, {})[var] = {}\n",
    "\n",
    "                    # tumor = sample at index -2, blood = sample at index -1 (your convention)\n",
    "                    ad_t = s[-2].split(':')[-1] if \":\" in s[-2] else s[-2]\n",
    "                    af_t, alt_t = parse_af(ad_t)\n",
    "                    ad_bl = s[-1].split(':')[-1] if \":\" in s[-1] else s[-1]\n",
    "                    af_bl, alt_bl = parse_af(ad_bl)\n",
    "\n",
    "                    dic_AF[mode][loc][var][\"l_t\"] = (af_t, alt_t)\n",
    "                    dic_AF[mode][loc][var][\"l_bl\"] = (af_bl, alt_bl)\n",
    "\n",
    "                    # Track tumor counts per (loc, REF) across all ALTs to decide major ALT\n",
    "                    ref_map = dic_tumor_counts[mode].setdefault(loc, {}).setdefault(ref, {})\n",
    "                    # use 0 if missing\n",
    "                    ref_map[alt] = alt_t if alt_t is not None else 0\n",
    "\n",
    "                    # Optionally store VAFs (unchanged from your code)\n",
    "                    variant = f\"{chrom}:{pos}:{ref}:{alt}\"\n",
    "                    dic_VAF[variant] = {\"VAF_pb\": af_t, \"VAF_ill\": None, \"VAF_bl\": af_bl}\n",
    "\n",
    "        # --- Validate against short-read calls (SNVs only as in your original input) ---\n",
    "        input_vcf = os.path.join(vcfpath, \"input\", f\"{mode}.snv.vcf.gz\")\n",
    "        with gzip.open(input_vcf, 'rt') as fin:\n",
    "            for line in fin:\n",
    "                if line.startswith(\"#\"):\n",
    "                    if not header_written:\n",
    "                        out_vcf.write(line)\n",
    "                        header_written = True\n",
    "                    continue\n",
    "\n",
    "                s = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "                if s[0] != chrom:\n",
    "                    continue\n",
    "\n",
    "                cnt_total += 1\n",
    "                pos, ref, alt = s[1], s[3], s[4]  # SNV here\n",
    "                loc, var = f\"{chrom}:{pos}\", f\"{ref}:{alt}\"\n",
    "                info = f\"{loc}:{var}\"\n",
    "                dic_raw_all.setdefault(info, []).append(tool)\n",
    "\n",
    "                # Must exist in PU dictionary to be considered\n",
    "                if (loc in dic_AF[mode]) and (var in dic_AF[mode][loc]):\n",
    "                    af_t, ad_t = dic_AF[mode][loc][var][\"l_t\"]\n",
    "                    af_bl, ad_bl = dic_AF[mode][loc][var][\"l_bl\"]\n",
    "\n",
    "                    if (af_t is not None) and (ad_t > 1):  # tumor supports alt\n",
    "                        cnt_alt_in_t += 1\n",
    "\n",
    "                        # any blood ALT evidence across ANY competing allele at this loc?\n",
    "                        blood_has_alt = any(\n",
    "                            (dic_AF[mode][loc][other][\"l_bl\"][1] or 0) > 2\n",
    "                            for other in dic_AF[mode][loc]\n",
    "                        )\n",
    "\n",
    "                        if (af_bl == 0.0 or af_bl is None) and not blood_has_alt:\n",
    "                            # --- Multi-allelic check: compare among ALTs with the SAME REF only ---\n",
    "                            ref_map = dic_tumor_counts[mode].get(loc, {}).get(ref, {})\n",
    "                            if ref_map:\n",
    "                                # counts for this ALT\n",
    "                                this_cnt = ref_map.get(alt, 0)\n",
    "                                # find major ALT and its count\n",
    "                                major_alt, major_cnt = max(ref_map.items(), key=lambda kv: kv[1] if kv[1] is not None else -1)\n",
    "                                # Mark multi-allelic ONLY if major strictly exceeds the current alt and alt differs\n",
    "                                if (alt != major_alt) and (major_cnt is not None) and (major_cnt > this_cnt):\n",
    "                                    dic_multiallelic[mode] += 1\n",
    "                                    cnt_multiallelic_chr += 1\n",
    "                                    # do NOT write to Valid.vcf\n",
    "                                    continue\n",
    "\n",
    "                            # Passes (not multi-allelic or it's the major ALT)\n",
    "                            cnt_noalt_in_bl += 1\n",
    "                            dic_valid[mode].append(loc)\n",
    "                            out_vcf.write(line)\n",
    "                            dic_step1[chrom].setdefault(info, []).append(tool)\n",
    "                        else:\n",
    "                            cnt_alt_in_bl += 1\n",
    "                    else:\n",
    "                        dic_altzero.setdefault(info, []).append(tool)\n",
    "                else:\n",
    "                    # no matching entry in PU table\n",
    "                    cnt_alt_notin_lt += 1\n",
    "\n",
    "        # --- Write per-chrom stats (as in your original, now with MultiAllelic this-chr) ---\n",
    "        valid_percent_chr = (cnt_noalt_in_bl / cnt_total * 100) if cnt_total else 0.0\n",
    "        out_stat.write(\n",
    "            f\"{mode}\\t{chrom}\\t{cnt_total}\\t{cnt_alt_in_t}\\t{cnt_noalt_in_bl}\\t\"\n",
    "            f\"{cnt_alt_in_bl}\\t{cnt_alt_notin_lt}\\t{cnt_alt_notin_st}\\t\"\n",
    "            f\"{cnt_multiallelic_chr}\\t{valid_percent_chr:.2f}\\n\"\n",
    "        )\n",
    "\n",
    "        # accumulate mode totals\n",
    "        m_total += cnt_total\n",
    "        m_alt_in_t += cnt_alt_in_t\n",
    "        m_valid += cnt_noalt_in_bl\n",
    "        m_alt_in_bl += cnt_alt_in_bl\n",
    "        m_alt_notin_lt += cnt_alt_notin_lt\n",
    "        m_alt_notin_st += cnt_alt_notin_st\n",
    "        m_multiallelic += cnt_multiallelic_chr\n",
    "\n",
    "        print(chrom, cnt_total, cnt_alt_in_t, cnt_noalt_in_bl, cnt_alt_in_bl, cnt_alt_notin_lt, cnt_multiallelic_chr)\n",
    "\n",
    "    out_vcf.close()\n",
    "    out_stat.close()\n",
    "\n",
    "    # --- Combined one-line-per-mode stat file ---\n",
    "    valid_percent_mode = (m_valid / m_total * 100) if m_total else 0.0\n",
    "    with open(combined_stat_path, \"a\") as fout:\n",
    "        fout.write(\n",
    "            f\"{mode}\\t{m_total}\\t{m_alt_in_t}\\t{m_valid}\\t{m_alt_in_bl}\\t\"\n",
    "            f\"{m_alt_notin_lt}\\t{m_alt_notin_st}\\t{m_multiallelic}\\t{valid_percent_mode:.2f}\\n\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f232a-d6e8-4892-9e69-277564d763ea",
   "metadata": {},
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "# --- Paths & setup ---\n",
    "path = \"/n/data1/hms/dbmi/park/jiny/SMaHT/COLO829/0.truthset/\"\n",
    "vcfpath = os.path.join(path, \"0.calls_Illumina\")\n",
    "outpath = os.path.join(path, \"1.Illumina_PU20\")\n",
    "chroms = [f\"chr{i}\" for i in range(1, 23)] + [\"chrX\", \"chrY\"]\n",
    "\n",
    "l_mode = {\"MT\", \"STK\", \"VN\", \"RF\"}\n",
    "\n",
    "# --- Dictionaries ---\n",
    "dic_raw_all, dic_step1, dic_AF, dic_valid, dic_altzero, dic_VAF = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "# --- Helpers ---\n",
    "def parse_af(ad_field):\n",
    "    \"\"\"Extract (AF, alt_count) from RO,AO string (AD).\"\"\"\n",
    "    try:\n",
    "        ref, alt = int(ad_field.split(',')[0]), int(ad_field.split(',')[1])\n",
    "        depth = ref + alt\n",
    "        if depth == 0:\n",
    "            return 0, 0\n",
    "        return float(alt) / depth, alt\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "# --- Main loop ---\n",
    "for mode in l_mode:\n",
    "    tool = mode.split(\".\")[0]\n",
    "    dic_valid[mode] = []\n",
    "    print(f\"\\n+++ {mode} started +++\")\n",
    "    out_vcf = open(f\"{outpath}/Valid_tools/{mode}.Valid.vcf\", \"w\")\n",
    "    out_stat = open(f\"{outpath}/Stat/Stat_snv_{mode}.Valid.txt\", \"a\")\n",
    "    out_stat.write(\"mode\\tchrom\\tTotal\\tAlt_in_T\\tValid\\tInvalid_Alt_in_LBL\\t\"\n",
    "                   \"Invalid_NoAlt_in_LT\\tInvalid_NoAlt_in_ST\\tValid_percent\\n\")\n",
    "\n",
    "    for chrom in chroms:\n",
    "        # --- Read PacBio support (PU file) ---\n",
    "        pu_file = os.path.join(vcfpath, \"PU_bcftools\", str(mode)+'.snv.' + chrom + \".PU.norm.vcf.gz\")\n",
    "        if mode not in dic_AF: dic_AF[mode] = {}\n",
    "        if chrom not in dic_step1: dic_step1[chrom] = {}\n",
    "\n",
    "        with open(pu_file) as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"#\"): continue\n",
    "                s = line.strip().split(\"\\t\")\n",
    "                if s[0] != chrom: continue\n",
    "                pos, ref, alt = s[1], s[3], s[4]\n",
    "                if alt == \"<*>\" or len(ref) != 1 or len(alt) != 1: continue\n",
    "                loc, var = f\"{chrom}:{pos}\", f\"{ref}:{alt}\"\n",
    "                variant = f\"{chrom}:{pos}:{ref}:{alt}\"\n",
    "                dic_AF[mode].setdefault(loc, {})[var] = {}\n",
    "                ad_t = s[-2].split(':')[-1]\n",
    "                af_t, alt_t = parse_af(ad_t)\n",
    "                ad_bl = s[-1].split(':')[-1]\n",
    "                af_bl, alt_bl = parse_af(ad_bl)\n",
    "                dic_AF[mode][loc][var][\"l_t\"] = (af_t, alt_t)\n",
    "                dic_AF[mode][loc][var][\"l_bl\"] = (af_bl, alt_bl)\n",
    "\n",
    "                # --- NEW: store PacBio tumor VAF and Illumina blood VAF ---\n",
    "                dic_VAF[variant] = {\n",
    "                    \"VAF_pb\": af_t,\n",
    "                    \"VAF_ill\": None,   # will be filled from pileups later\n",
    "                    \"VAF_bl\": af_bl\n",
    "                }\n",
    "\n",
    "        # --- Validate against short-read calls ---\n",
    "        cnt_total = cnt_alt_in_t = cnt_noalt_in_bl = cnt_alt_in_bl = cnt_alt_notin_lt = cnt_alt_notin_st = 0\n",
    "        header_written = False\n",
    "\n",
    "        with gzip.open(vcfpath + '/input/' + mode + '.snv.vcf.gz', 'rt') as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"#\"):\n",
    "                    if not header_written:\n",
    "                        out_vcf.write(line)\n",
    "                        header_written = True\n",
    "                    continue\n",
    "                s = line.strip().split(\"\\t\")\n",
    "                if s[0] != chrom: continue\n",
    "                cnt_total += 1\n",
    "                pos, ref, alt = s[1], s[3], s[4]\n",
    "                loc, var = f\"{chrom}:{pos}\", f\"{ref}:{alt}\"\n",
    "                info = f\"{loc}:{var}\"\n",
    "                dic_raw_all.setdefault(info, []).append(tool)\n",
    "                if loc in dic_AF[mode] and var in dic_AF[mode][loc]:\n",
    "                    af_t, ad_t = dic_AF[mode][loc][var][\"l_t\"]\n",
    "                    af_bl, ad_bl = dic_AF[mode][loc][var][\"l_bl\"]\n",
    "                    if af_t and af_t > 0:  # tumor supports alt\n",
    "                        cnt_alt_in_t += 1\n",
    "                        blood_has_alt = any(\n",
    "                            dic_AF[mode][loc][other][\"l_bl\"][1] > 2\n",
    "                            for other in dic_AF[mode][loc]\n",
    "                        )\n",
    "                        if af_bl == 0 and not blood_has_alt:  # valid\n",
    "                            cnt_noalt_in_bl += 1\n",
    "                            dic_valid[mode].append(loc)\n",
    "                            out_vcf.write(line)\n",
    "                            dic_step1[chrom].setdefault(info, []).append(tool)\n",
    "                        else:\n",
    "                            cnt_alt_in_bl += 1\n",
    "                    else:\n",
    "                        dic_altzero.setdefault(info, []).append(tool)\n",
    "                else:\n",
    "                    cnt_alt_notin_lt += 1\n",
    "\n",
    "        # --- Write stats ---\n",
    "        out_stat.write(\n",
    "            f\"{mode}\\t{chrom}\\t{cnt_total}\\t{cnt_alt_in_t}\\t{cnt_noalt_in_bl}\\t\"\n",
    "            f\"{cnt_alt_in_bl}\\t{cnt_alt_notin_lt}\\t{cnt_alt_notin_st}\\n\"\n",
    "        )\n",
    "        print(chrom, cnt_total, cnt_alt_in_t, cnt_noalt_in_bl, cnt_alt_in_bl, cnt_alt_notin_lt)\n",
    "\n",
    "    out_vcf.close()\n",
    "    out_stat.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7d38175-f744-4dd7-8076-ea85b7df5169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61648\n",
      "44005\n"
     ]
    }
   ],
   "source": [
    "print (len(dic_raw_all))\n",
    "l_chrom= ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']\n",
    "\n",
    "cnt = 0\n",
    "for chrom in dic_step1:\n",
    "    cnt += len(dic_step1[chrom])\n",
    "print (cnt)\n",
    "out_snv = open(\"/n/data1/hms/dbmi/park/jiny/SMaHT/COLO829/0.truthset/1.Illumina_PU20/Step1_Validated_union_snv.vcf\", 'w')\n",
    "vcf_header = \"##fileformat=VCFv4.2\\n##INFO=<ID=SP,Number=1,Type=String,Description='Variant caller supported this variant'>\\n#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\tCOLO829T\\n\"\n",
    "\n",
    "out_snv.write(vcf_header)\n",
    "\n",
    "for chr_each in l_chrom:\n",
    "    dic_bypos = {} #For sorting pos\n",
    "    l_bypos = []\n",
    "    for info in dic_step1[chr_each]:\n",
    "        s = info.split(':')\n",
    "        chrom, pos, ref, alt = s[0], int(s[1]), s[2], s[3]\n",
    "        dic_bypos[pos] = info\n",
    "        l_bypos.append(pos)\n",
    "    l_bypos.sort()\n",
    "    \n",
    "    for pos in l_bypos:\n",
    "        info = dic_bypos[pos]\n",
    "        chrom, pos, ref, alt = s[0], s[1], s[2], s[3]\n",
    "        s = info.split(':')\n",
    "        chrom, pos, ref, alt = s[0], int(s[1]), s[2], s[3]\n",
    "        \n",
    "        l_tool= dic_step1[chrom][info]\n",
    "        tool_support = ','.join(l_tool)\n",
    "        out_snv.write(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" %(chrom, str(pos), '.', ref, alt, '.', '.', 'SP='+ tool_support, '.\\t.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "839e82b5-b97d-43ac-8c78-33ee5d90ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1:887559:C:T {'VAF_pb': 1.0, 'VAF_ill': None, 'VAF_bl': 0.0}\n"
     ]
    }
   ],
   "source": [
    "for var in dic_VAF:\n",
    "    print (var, dic_VAF[var])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41d271b9-e700-466d-8032-55db4d56d493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::vcf_parse] Contig 'chr1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr2' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr3' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr4' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr5' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr6' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr7' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr8' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr9' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr10' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr11' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr12' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr13' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr14' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr15' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr16' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr17' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr18' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr19' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr20' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr21' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr22' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chrX' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr2' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr3' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr4' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr5' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr6' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr7' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr8' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr9' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr10' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr11' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr12' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr13' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr14' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr15' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr16' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr17' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr18' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr19' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr20' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr21' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr22' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chrX' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chrY' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr2' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr3' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr4' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr5' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr6' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr7' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr8' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr9' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr10' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr11' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr12' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr13' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr14' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr15' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr16' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr17' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr18' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr19' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr20' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr21' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr22' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chrX' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chrY' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr2' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr3' is not defined in the header. (Quick workaround: index the file with tabix.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG chr1:183180:G:A -> VAF_PB=0.025 VAF_Ill=0.16467780429594273  RGN=Extreme\n",
      "DEBUG chr1:183198:C:T -> VAF_PB=0.02631578947368421 VAF_Ill=0.14733542319749215  RGN=Extreme\n",
      "DEBUG chr1:601606:G:T -> VAF_PB=0.3333333333333333 VAF_Ill=0.8648648648648649  RGN=Extreme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::vcf_parse] Contig 'chr4' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr5' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr6' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr7' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr8' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr9' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr10' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr11' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr12' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr13' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr14' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr15' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr16' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr17' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr18' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr19' is not defined in the header. (Quick workaround: index the file with tabix.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output written: /n/data1/hms/dbmi/park/jiny/SMaHT/COLO829/0.truthset/2.PacBio_Valid/Step1_Validated_union_snv_VAF_RGN.vcf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::vcf_parse] Contig 'chr20' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr21' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chr22' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chrX' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'chrY' is not defined in the header. (Quick workaround: index the file with tabix.)\n"
     ]
    }
   ],
   "source": [
    "import pysam\n",
    "import gzip\n",
    "\n",
    "# --- Function to parse VAF from pileup FORMAT ---\n",
    "def get_VAF_from_pileup(ad_field):\n",
    "    try:\n",
    "        ref, alt = int(ad_field.split(',')[0]), int(ad_field.split(',')[1])\n",
    "        depth = ref + alt\n",
    "        if depth == 0:\n",
    "            return 0\n",
    "    except Exception:\n",
    "        return None\n",
    "    return float(alt)/depth\n",
    "\n",
    "# --- Load Illumina tumor VAFs from per-chrom pileups ---\n",
    "pileup_dir = \"/n/data1/hms/dbmi/park/jiny/SMaHT/COLO829/0.truthset/2.PacBio_Valid/PU_bcftools\"\n",
    "dic_IllT = {}\n",
    "\n",
    "chroms = [f\"chr{i}\" for i in range(1, 23)] + [\"chrX\", \"chrY\"]\n",
    "for chrom in chroms:\n",
    "    pileup_file = f\"{pileup_dir}/Step1_Validated_union.{chrom}.PU.norm.vcf.gz\"\n",
    "    with open(pileup_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            s = line.strip().split(\"\\t\")\n",
    "            chrom_v, pos, ref, alt,  sample = s[0], s[1], s[3], s[4], s[-1]\n",
    "            if alt == \"<*>\":\n",
    "                continue\n",
    "            variant = \":\".join([chrom_v, pos, ref, alt])\n",
    "            vaf_ill = get_VAF_from_pileup(sample.split(':')[-1])\n",
    "            dic_IllT[variant] = vaf_ill\n",
    "#print (dic_IllT)\n",
    "# --- Load Region stratification ---\n",
    "region_vcfs = {\n",
    "    \"Easy\":      \"/n/data1/hms/dbmi/park/jiny/SMaHT/COLO829/0.truthset/2.PacBio_Valid/Region_snv/Step1_Validated_union_snv.SMaHT_easy_v2.bed.gz.vcf\",\n",
    "    \"Difficult\": \"/n/data1/hms/dbmi/park/jiny/SMaHT/COLO829/0.truthset/2.PacBio_Valid/Region_snv/Step1_Validated_union_snv.SMaHT_difficult_v2.bed.gz.vcf\",\n",
    "    \"Extreme\":   \"/n/data1/hms/dbmi/park/jiny/SMaHT/COLO829/0.truthset/2.PacBio_Valid/Region_snv/Step1_Validated_union_snv.SMaHT_extreme_v2.bed.gz.vcf\",\n",
    "}\n",
    "\n",
    "region_map = {}\n",
    "for region, path in region_vcfs.items():\n",
    "    with pysam.VariantFile(path) as rv:\n",
    "        for rec in rv.fetch():\n",
    "            variant = f\"{rec.chrom}:{rec.pos}:{rec.ref}:{rec.alts[0]}\"\n",
    "            region_map[variant] = region\n",
    "\n",
    "# --- Input and output ---\n",
    "input_vcf_path  = \"/n/data1/hms/dbmi/park/jiny/SMaHT/COLO829/0.truthset/2.PacBio_Valid/Step1_Validated_union_snv.vcf\"\n",
    "output_vcf_path = input_vcf_path[:-4] + \"_VAF_RGN.vcf\"\n",
    "\n",
    "vcf_in = pysam.VariantFile(input_vcf_path, \"r\")\n",
    "\n",
    "# --- Copy header and add contigs + INFO fields ---\n",
    "new_header = vcf_in.header.copy()\n",
    "\n",
    "# Ensure all typical chr contigs exist (prevents ValueError: Invalid chromosome/contig)\n",
    "for c in chroms:\n",
    "    if c not in new_header.contigs:\n",
    "        new_header.contigs.add(c)\n",
    "\n",
    "# Add new INFO fields if missing\n",
    "for field, num, ftype, desc in [\n",
    "    (\"VAF_Ill\", 1, \"Float\",  \"Variant allele frequency in 200X Illumina COLO829T (pileup-based)\"),\n",
    "    (\"VAF_PB\",  1, \"Float\",  \"Variant allele frequency in 180X PacBio COLO829T\"),\n",
    "    (\"VAF_BL\",  1, \"Float\",  \"Variant allele frequency in 230X Illumina COLO829BL\"),\n",
    "    (\"RGN\",     1, \"String\", \"SMaHT region stratification: Easy, Difficult, or Extreme\"),\n",
    "]:\n",
    "    if field not in new_header.info:\n",
    "        new_header.info.add(field, num, ftype, desc)\n",
    "\n",
    "# --- Open output with modified header ---\n",
    "vcf_out = pysam.VariantFile(output_vcf_path, \"w\", header=new_header)\n",
    "\n",
    "# --- Iterate records ---\n",
    "n_debug = 0\n",
    "for rec in vcf_in.fetch():\n",
    "    # Build variant key\n",
    "    if not rec.alts:\n",
    "        continue\n",
    "    variant = f\"{rec.chrom}:{rec.pos}:{rec.ref}:{rec.alts[0]}\"\n",
    "\n",
    "    # Create new record bound to new_header\n",
    "    new_rec = vcf_out.new_record(\n",
    "        contig=rec.chrom,\n",
    "        start=rec.start,\n",
    "        stop=rec.stop,\n",
    "        alleles=rec.alleles,\n",
    "        id=rec.id,\n",
    "        qual=rec.qual,\n",
    "        filter=list(rec.filter.keys()),\n",
    "    )\n",
    "\n",
    "    # Copy original INFO keys that exist in new_header\n",
    "    for k, v in rec.info.items():\n",
    "        if k in new_header.info:\n",
    "            try:\n",
    "                new_rec.info[k] = v\n",
    "            except Exception:\n",
    "                # Skip incompatible array/scalar mismatches silently\n",
    "                pass\n",
    "\n",
    "    # Copy samples/FORMAT (so you keep the original sample column)\n",
    "    for sample in rec.samples:\n",
    "        new_rec.samples[sample].update(rec.samples[sample])\n",
    "\n",
    "    # Fetch VAFs and region\n",
    "    # NOTE: dic_VAF must be present in the session (built by your first script)\n",
    "    vaf_pb  = dic_VAF.get(variant, {}).get(\"VAF_pb\")\n",
    "   # vaf_bl  = dic_VAF.get(variant, {}).get(\"VAF_bl\")\n",
    "    vaf_ill = dic_IllT[variant]\n",
    "    #print (variant, vaf_ill)\n",
    "    region  = region_map.get(variant)\n",
    "\n",
    "    if vaf_pb is not None:\n",
    "        new_rec.info[\"VAF_PB\"] = float(round(vaf_pb, 6))\n",
    "    if vaf_ill is not None:\n",
    "        new_rec.info[\"VAF_Ill\"] = float(round(vaf_ill, 6))\n",
    "    if region:\n",
    "        new_rec.info[\"RGN\"] = region\n",
    "\n",
    "    vcf_out.write(new_rec)\n",
    "\n",
    "    # Optional quick debug for first few records\n",
    "    if n_debug < 3:\n",
    "        print(f\"DEBUG {variant} -> VAF_PB={vaf_pb} VAF_Ill={vaf_ill}  RGN={region}\")\n",
    "        n_debug += 1\n",
    "\n",
    "vcf_in.close()\n",
    "vcf_out.close()\n",
    "\n",
    "print(f\"✅ Output written: {output_vcf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027a79b-e99b-48df-8e7c-bdcb6c20f2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490151d-f16c-415d-8d71-e6a57933fcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b055b-0902-491d-9664-3d74695bb534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09c76e-f8b6-4fbc-b094-80323d85c495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
